@inproceedings{IaAEC_in_RS,
  author={Karakolis, Evangelos and Oikonomidis, Panagiotis Foivos and Askounis, Dimitrios},
  booktitle={2022 13th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Identifying and Addressing Ethical Challenges in Recommender Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  keywords={Ethics;Data privacy;Information filters;Artificial intelligence;Recommender systems;Digital Ethics;Recommender Systems;Ethical Data Processing;Ethical Challenges;Multi-stakeholder recommender systems},
  doi={10.1109/IISA56318.2022.9904386}}
@INPROCEEDINGS{7956539,
  author={Paraschakis, Dimitris},
  booktitle={2017 11th International Conference on Research Challenges in Information Science (RCIS)}, 
  title={Towards an ethical recommendation framework}, 
  year={2017},
  volume={},
  number={},
  pages={211-220},
  abstract={The goal of our study is to provide a holistic view on various ethical challenges that complicate the design and use of recommender systems (RS). Our findings materialize into an ethical recommendation framework, which maps RS development stages to the corresponding ethical concerns, and further down to known solutions and the proposed user-adjustable controls. The need for such a framework is dictated by the apparent lack of research in this particular direction and the severity of consequences stemming from the neglect of the code of ethics in recommendations. The framework aims to aid RS practitioners in staying ethically alert while taking morally charged design decisions. At the same time, it would give users the desired control over the sensitive moral aspects of recommendations via the proposed “ethical toolbox”. The idea is embraced by the participants of our feasibility study.},
  keywords={Ethics;Recommender systems;Privacy;Data privacy;Motion pictures;History;Data collection;recommender systems;ethics;ethical recommendation framework},
  doi={10.1109/RCIS.2017.7956539},
  ISSN={2151-1357},
  month={May}}
@article{F_RS,
title = {User modeling via stereotypes},
journal = {Cognitive Science},
volume = {3},
number = {4},
pages = {329-354},
year = {1979},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(79)80012-9},
url = {https://www.sciencedirect.com/science/article/pii/S0364021379800129},
author = {Elaine Rich},
abstract = {This paper addresses the problems that must be considered if computers are going to treat their users as individuals with distinct personalities, goals, and so forth. It first outlines the issues, and then proposes stereotypes as a useful mechanism for building models of individual users on the basis of a small amount of information about them. In order to build user models quickly, a large amount of uncertain knowledge must be incorporated into the models. The issue of how to resolve the conflicts that will arise among such inferences is discussed. A system, Grundy, is described that builds models of its users, with the aid of stereotypes, and then exploits those models to guide it in its task, suggesting novels that people may find interesting. If stereotypes are to be useful to Grundy, they must accurately characterize the users of the system. Some techniques to modify stereotypes on the basis of experience are discussed. An analysis of Grundy's performance shows that its user models are effective in guiding its performance.}
}
@book{RS,
  author    = {Charu C. Aggarwal},
  title     = {Recommender Systems: The Textbook},
  year      = {2016},
  publisher = {Springer Cham},
  doi       = {10.1007/978-3-319-29659-3},
  isbn      = {978-3-319-29659-3},
  edition   = {1},
  pages     = {XXI, 498},
  keywords  = {Data Mining and Knowledge Discovery, Artificial Intelligence}
}
@Inbook{RS_AA_2,
author="Kar, Pushpendu
and Roy, Monideepa
and Datta, Sujoy",
title="Overview of Recommendation Systems",
bookTitle="Recommender Systems: Algorithms and their Applications",
year="2024",
publisher="Springer Nature Singapore",
address="Singapore",
pages="11--17",
abstract="In this chapter, an overview of the recommendationRecommendation algorithmsAlgorithm is given. The chapter deals with the goals of a recommender systemRecommender system and discusses the wide spectrum of applications they can be applied for. Some very successful business models which run on recommendationRecommendation systems have also been discussed here. After that a classification of the different types of recommendationRecommendation systems is given, followed by the specific challenges faced for domains.",
isbn="978-981-97-0538-2",
doi="10.1007/978-981-97-0538-2_2",
url="https://doi.org/10.1007/978-981-97-0538-2_2"
}
@Inbook{RS_AA_3,
author="Kar, Pushpendu
and Roy, Monideepa
and Datta, Sujoy",
title="Collaborative Filtering and Content-Based Systems",
bookTitle="Recommender Systems: Algorithms and their Applications",
year="2024",
publisher="Springer Nature Singapore",
address="Singapore",
pages="19--30",
abstract="In this chapter, the two most widely used types of recommender systemsRecommender system, namely the collaborative filteringCollaborative filtering method and the content-based system, along with a few of their important sub-types are discussed in this chapter. There are two types of collaborative methods, namely the neighborhood-based and model-basedModel-based methods. The chapter discusses what are the features of and differences between the two methods. The basic components of the content-based systems are also discussed. Both the systems have their advantages and disadvantages which are also discussed here.",
isbn="978-981-97-0538-2",
doi="10.1007/978-981-97-0538-2_3",
url="https://doi.org/10.1007/978-981-97-0538-2_3"
}
@Inbook{RS_AA_5,
author="Aggarwal, Charu C.",
title="Knowledge-Based Recommender Systems",
bookTitle="Recommender Systems: The Textbook",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="167--197",
abstract="Both content-based and collaborative systems require a significant amount of data about past buying and rating experiences. For example, collaborative systems require a reasonably well populated ratings matrix to make future recommendations. In cases where the amount of available data is limited, the recommendations are either poor, or they lack full coverage over the entire spectrum of user-item combinations.",
isbn="978-3-319-29659-3",
doi="10.1007/978-3-319-29659-3_5",
url="https://doi.org/10.1007/978-3-319-29659-3_5"
}
@article{AI_in_RS,
author = {Zhang, Qian and Lu, Jie and Jin, Yaochu},
year = {2020},
month = {11},
pages = {},
title = {Artificial intelligence in recommender systems},
volume = {7},
journal = {Complex & Intelligent Systems},
doi = {10.1007/s40747-020-00212-w}
}
@book{RS_ELI,
  title={Recommender Systems: Legal and Ethical Issues},
  editor={Genovesi, Sergio and Kaesling, Katharina and Robbins, Scott},
  series={The International Library of Ethics, Law and Technology},
  publisher={Springer Cham},
  year={2023},
  edition={1},
  pages={VI, 222},
  isbn={978-3-031-34803-7},
  eisbn={978-3-031-34804-4},
  doi={10.1007/978-3-031-34804-4},
  copyright={The Editor(s) and The Author(s) 2023},
}
﻿@Article{FB,
author={Rodilosso, Ermelinda},
title={Filter Bubbles and the Unfeeling: How AI for Social Media Can Foster Extremism and Polarization},
journal={Philosophy {\&} Technology},
year={2024},
month={Jun},
day={07},
volume={37},
number={2},
pages={71},
abstract={Social media have undoubtedly changed our ways of living. Their presence concerns an increasing number of users (over 4,74 billion) and pervasively expands in the most diverse areas of human life. Marketing, education, news, data, and sociality are just a few of the many areas in which social media play now a central role. Recently, some attention toward the link between social media and political participation has emerged. Works in the field of artificial intelligence have already pointed out that there is a close link between the use of machine learning algorithms in social media and possible epistemic isolation, which could lead to political radicalization. The idea supporting this paper is that artificial intelligence for social media can actively put users' deliberative capacity at risk and foster political extremism. To prove these claims, I proceed along two lines of inquiry. First, I focus on filter bubbles, namely the result of selections made by algorithms that recommend contents that meet users' expectations and opinions. To analyze this phenomenon, I refer to the Deweyan model of experience. Second, I connect the filter bubbles problem to the Deweyan idea of deliberative and participatory democracy and Nussbaum's concept of political compassion. The purpose of this paper is to provide a philosophical foundation that can both (1) effectively serve as a method for analyzing machine learning algorithms and their potential problems in relation to political extremism, and (2) be adopted as a standard to counter the danger of extremism associated with social media experience.},
issn={2210-5441},
doi={10.1007/s13347-024-00758-4},
url={https://doi.org/10.1007/s13347-024-00758-4}
}